{
  "script_name": "eval_ppl.py",
  "run_id": "20260124_045435",
  "timestamp_local": "2026-01-24 04:54:35",
  "time_run_s": 244.73783373832703,
  "time_run_hms": "4m 04s",
  "args": {
    "model_name": "Qwen/Qwen3-32B",
    "model_dir": "/root/cache/transformers/Qwen/Qwen3-32B",
    "dtype": "bf16",
    "load_in_8bit": true,
    "load_in_4bit": false,
    "compressor": "hqq",
    "max_length": 2048,
    "stride": 512,
    "first_k_tokens": 100000,
    "batch_windows": 2
  },
  "results": {
    "avg_ppl": 6.683519397755016,
    "total_nll": 189962.57083129883,
    "total_loss_tokens": 99999
  },
  "traffic_totals": {
    "total_bytes": 4549413012.0,
    "total_tokens": 1579648.0,
    "total_tx": 388.0,
    "bytes_per_token": 2880.016948079572
  },
  "traffic_per_link": {
    "layer:7:node0->node1:hqq": {
      "bytes": 1137353253,
      "tokens": 394912,
      "tx": 97
    },
    "layer:23:node1->node2:hqq": {
      "bytes": 1137353253,
      "tokens": 394912,
      "tx": 97
    },
    "layer:39:node2->node3:hqq": {
      "bytes": 1137353253,
      "tokens": 394912,
      "tx": 97
    },
    "layer:55:node3->node0:hqq": {
      "bytes": 1137353253,
      "tokens": 394912,
      "tx": 97
    }
  }
}